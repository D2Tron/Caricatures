{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9b08627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torch import nn\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.io import read_image\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import math\n",
    "import wandb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b06768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Variables\n",
    "device = (\"cpu\") # Use GPU or CPU for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b392863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Jayam\\OneDrive\\Desktop\\School Work\\Grad school\\Research Work\\for Jay\\wandb\\run-20230403_030338-zaz9ua0y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/unrmpl/my-awesome-project/runs/zaz9ua0y' target=\"_blank\">pleasant-star-17</a></strong> to <a href='https://wandb.ai/unrmpl/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/unrmpl/my-awesome-project' target=\"_blank\">https://wandb.ai/unrmpl/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/unrmpl/my-awesome-project/runs/zaz9ua0y' target=\"_blank\">https://wandb.ai/unrmpl/my-awesome-project/runs/zaz9ua0y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/unrmpl/my-awesome-project/runs/zaz9ua0y?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1bc15d70df0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a91a4bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new model\n",
    "class CaricatureClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.model_wo_fc = nn.Sequential(*list(self.model.children())[:-1])\n",
    "\n",
    "        self.cheekbones = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.cheeks = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.chin = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.ears = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.eyebrows = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.eyelids = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.eyes = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.facial_hair = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.forehead = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.hair = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.lips = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.mouth = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.neck = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.nose = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.skin = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.teeth = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.upper_lip = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(2048, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model_wo_fc(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return [\n",
    "            self.cheekbones(x),\n",
    "            self.cheeks(x),\n",
    "            self.chin(x),\n",
    "            self.ears(x),\n",
    "            self.eyebrows(x),\n",
    "            self.eyelids(x),\n",
    "            self.eyes(x),\n",
    "            self.facial_hair(x),\n",
    "            self.forehead(x),\n",
    "            self.hair(x),\n",
    "            self.head(x),\n",
    "            self.lips(x),\n",
    "            self.mouth(x),\n",
    "            self.neck(x),\n",
    "            self.nose(x),\n",
    "            self.skin(x),\n",
    "            self.teeth(x),\n",
    "            self.upper_lip(x)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2a777e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Create Dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "class CaricatureDataset(Dataset):\n",
    "    def __init__(self, labels_file, root_dir, transform=None):\n",
    "        self.labels = pd.read_csv(labels_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # This will read the first 5 images per person, this can probably be tweaked to include all images\n",
    "        class_index = math.floor(idx/5)\n",
    "        image_num = idx%5\n",
    "        self_car = self.labels.iloc[class_index, 0].strip() + \"_caricature\"\n",
    "        img_person = os.path.join(self.root_dir, self_car)\n",
    "        labels = self.labels.iloc[class_index, 1].replace('[', '').replace(']', '').split('.')[:-1]\n",
    "        labels = np.array([int(label) for label in labels])\n",
    "        img = read_image(os.path.join(img_person, os.listdir(img_person)[image_num]))\n",
    "        if img.shape[0] == 1:\n",
    "            img = np.repeat(img, 3, axis=0)\n",
    "        sample = img, labels\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfa14023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Load the data\n",
    "dataset = CaricatureDataset(labels_file='binary_labels.txt', root_dir='C:\\\\Users\\\\Jayam\\\\OneDrive\\\\Desktop\\\\School Work\\\\Grad school\\\\Research Work\\\\for Jay\\\\ourcar\\\\', transform=transform)\n",
    "#   Split the data into train and test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "#   Create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "126c9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CaricatureClassifier()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "\n",
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        del data\n",
    "        inputs, labels = inputs.float(), labels.float()\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        output = model(inputs)\n",
    "        del inputs\n",
    "        output = torch.stack(output, dim=1)\n",
    "        output = output.squeeze(2)\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(output, labels)\n",
    "        del output\n",
    "        del labels\n",
    "        loss.backward()\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss / 10 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            #tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            #tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            #print(\"Loss/train\", last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da4560a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 10 loss: 0.630774837732315\n",
      "  batch 20 loss: 0.5431512057781219\n",
      "  batch 30 loss: 0.49928970336914064\n",
      "  batch 40 loss: 0.5066579073667526\n",
      "LOSS train 0.5066579073667526 valid 0.4768437147140503\n",
      "EPOCH 2:\n",
      "  batch 10 loss: 0.42252751588821413\n",
      "  batch 20 loss: 0.4167929828166962\n",
      "  batch 30 loss: 0.3955605447292328\n",
      "  batch 40 loss: 0.43686647415161134\n",
      "LOSS train 0.43686647415161134 valid 0.45564791560173035\n",
      "EPOCH 3:\n",
      "  batch 10 loss: 0.3752384901046753\n",
      "  batch 20 loss: 0.34369239807128904\n",
      "  batch 30 loss: 0.34292306900024416\n",
      "  batch 40 loss: 0.3685119181871414\n",
      "LOSS train 0.3685119181871414 valid 0.4269651174545288\n",
      "EPOCH 4:\n",
      "  batch 10 loss: 0.2868205100297928\n",
      "  batch 20 loss: 0.2739515021443367\n",
      "  batch 30 loss: 0.28700122237205505\n",
      "  batch 40 loss: 0.2815452665090561\n",
      "LOSS train 0.2815452665090561 valid 0.43192604184150696\n",
      "EPOCH 5:\n",
      "  batch 10 loss: 0.24500191509723662\n",
      "  batch 20 loss: 0.2728478744626045\n",
      "  batch 30 loss: 0.23853281289339065\n",
      "  batch 40 loss: 0.23040230125188826\n",
      "LOSS train 0.23040230125188826 valid 0.4443759024143219\n",
      "EPOCH 6:\n",
      "  batch 10 loss: 0.20458053946495056\n",
      "  batch 20 loss: 0.22872698158025742\n",
      "  batch 30 loss: 0.24375921338796616\n",
      "  batch 40 loss: 0.2399851381778717\n",
      "LOSS train 0.2399851381778717 valid 0.4442674517631531\n",
      "EPOCH 7:\n",
      "  batch 10 loss: 0.18883225619792937\n",
      "  batch 20 loss: 0.2059978127479553\n",
      "  batch 30 loss: 0.2215517796576023\n",
      "  batch 40 loss: 0.19912557750940324\n",
      "LOSS train 0.19912557750940324 valid 0.43610334396362305\n",
      "EPOCH 8:\n",
      "  batch 10 loss: 0.18408652916550636\n",
      "  batch 20 loss: 0.15864443704485892\n",
      "  batch 30 loss: 0.21187181994318963\n",
      "  batch 40 loss: 0.19021708369255066\n",
      "LOSS train 0.19021708369255066 valid 0.4555971026420593\n",
      "EPOCH 9:\n",
      "  batch 10 loss: 0.16935375556349755\n",
      "  batch 20 loss: 0.14944177269935607\n",
      "  batch 30 loss: 0.16175277084112166\n",
      "  batch 40 loss: 0.17445366755127906\n",
      "LOSS train 0.17445366755127906 valid 0.41397562623023987\n",
      "EPOCH 10:\n",
      "  batch 10 loss: 0.16011101827025415\n",
      "  batch 20 loss: 0.14743969365954399\n",
      "  batch 30 loss: 0.1718788154423237\n",
      "  batch 40 loss: 0.16432617530226706\n",
      "LOSS train 0.16432617530226706 valid 0.44157397747039795\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "epoch_number = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "\n",
    "    # We don't need gradients on to do reporting\n",
    "    model.train(False)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    for i, vdata in enumerate(test_loader):\n",
    "        vinputs, vlabels = vdata\n",
    "        del vdata\n",
    "        vinputs, vlabels = vinputs.float(), vlabels.float()\n",
    "        voutputs = model(vinputs)\n",
    "        del vinputs\n",
    "        voutputs = torch.stack(voutputs, dim=1)\n",
    "        voutputs = voutputs.squeeze(2)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        del vlabels\n",
    "        del voutputs\n",
    "        running_vloss += vloss\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "#     writer.add_scalars('Training vs. Validation Loss',\n",
    "#                     { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "#                     epoch_number + 1)\n",
    "#     writer.flush()\n",
    "\n",
    "    #wandb.log({ 'Training' : avg_loss, 'Validation' : avg_vloss })\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "#     if avg_vloss < best_vloss:\n",
    "#         best_vloss = avg_vloss\n",
    "#         model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "#         torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "205946bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7ac5549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_true_labels = np.array([])\n",
    "    all_predictions = np.array([])\n",
    "    all_true_labels_itemized = np.zeros([1,18])\n",
    "    all_predictions_itemized = np.zeros([1,18])\n",
    "    with torch.no_grad():\n",
    "        print(len(test_loader))\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.float(), target.float()\n",
    "            output = model(data)\n",
    "            outputs = torch.stack(output, dim=1)\n",
    "            predictions = np.round(outputs.detach().cpu().numpy())\n",
    "            labels = target.detach().cpu().numpy()\n",
    "            all_true_labels = np.append(all_true_labels, labels)\n",
    "            all_predictions = np.append(all_predictions, predictions)\n",
    "            predictions = predictions.transpose()\n",
    "            all_true_labels_itemized = np.concatenate((all_true_labels_itemized, labels), axis=0)\n",
    "            all_predictions_itemized = np.concatenate((all_predictions_itemized, predictions[0].T), axis=0)\n",
    "    for index, prediction in enumerate(all_predictions):\n",
    "        if prediction == all_true_labels[index]:\n",
    "            correct += 1\n",
    "    print('Accuracy: ', correct/len(all_predictions))\n",
    "    print('Confusion Matrix: ', multilabel_confusion_matrix(all_true_labels, all_predictions))\n",
    "    return all_true_labels_itemized, all_predictions_itemized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dda2082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Accuracy:  0.7859078590785907\n",
      "Confusion Matrix:  [[[153  90]\n",
      "  [ 68 427]]\n",
      "\n",
      " [[427  68]\n",
      "  [ 90 153]]]\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = testing(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c5658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
